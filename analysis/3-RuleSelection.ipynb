{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import ast\n",
    "\n",
    "NAFILL = -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config_general.json\", \"r\") as f:\n",
    "    config_general = json.load(f)\n",
    "folder_path = config_general[\"data_root_path\"]\n",
    "epis = config_general[\"epis\"]\n",
    "wks = config_general[\"wks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_specific_filename = \"config_specific_cmu_two_non_overlap.json\"\n",
    "with open(config_specific_filename, \"r\") as f:\n",
    "    config_specific = json.load(f)\n",
    "print(config_specific)\n",
    "focus_path = folder_path + \"Selection_Group/\" + config_specific[\"label_focus\"] + \"/\"\n",
    "if (not os.path.exists(focus_path)):\n",
    "    os.mkdir(focus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_filter(df, minsupp, minconf, minlift = -1, lift_valid = True):\n",
    "    df_filtered = deepcopy(df)\n",
    "    if (lift_valid):\n",
    "        df_filtered = df_filtered[\n",
    "            (\n",
    "                (\n",
    "                (df_filtered[\"supp\" + '_grp1'] >= minsupp) &\n",
    "                (df_filtered[\"conf\" + '_grp1'] >= minconf) &\n",
    "                (df_filtered[\"lift\" + '_grp1'] >= minlift)\n",
    "                ) \n",
    "                |\n",
    "                (\n",
    "                (df_filtered[\"supp\" + '_grp2'] >= minsupp) &\n",
    "                (df_filtered[\"conf\" + '_grp2'] >= minconf) &\n",
    "                (df_filtered[\"lift\" + '_grp2'] >= minlift)\n",
    "                )\n",
    "            )]\n",
    "    else:\n",
    "        df_filtered = df_filtered[\n",
    "            (\n",
    "                (\n",
    "                (df_filtered[\"supp\" + '_grp1'] >= minsupp) &\n",
    "                (df_filtered[\"conf\" + '_grp1'] >= minconf)\n",
    "                ) \n",
    "                |\n",
    "                (\n",
    "                (df_filtered[\"supp\" + '_grp2'] >= minsupp) &\n",
    "                (df_filtered[\"conf\" + '_grp2'] >= minconf)\n",
    "                )\n",
    "            )]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nostraight_pair_rulenum(df):\n",
    "    return sum((df[\"idx_grp1\"] == 0) | (df[\"idx_grp2\"] == 0))\n",
    "def nostraight_paired(df):\n",
    "    return df[(df[\"idx_grp1\"] == 0) | (df[\"idx_grp2\"] == 0)]\n",
    "def straight_paired(df):\n",
    "    return df[(df[\"idx_grp1\"] != 0) & (df[\"idx_grp2\"] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_combined_asso = {}\n",
    "for wk in wks:\n",
    "    dfs_combined_asso[wk] = {}\n",
    "    for epi in epis:\n",
    "        print(wk, epi)\n",
    "        filename = \"asso_\" + wk + \"_\" + epi\n",
    "#         df_grp1 = pd.read_excel(grp_spmf_parse + filename + \"_grp1.xlsx\")\n",
    "#         df_grp2 = pd.read_excel(grp_spmf_parse + filename + \"_grp2.xlsx\")\n",
    "        df_combine = pd.read_csv(focus_path + \"SPMF_parse/\" + filename + \"_combine.csv\")\n",
    "        dfs_combined_asso[wk][epi] = deepcopy(df_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_filtered_asso = {}\n",
    "dfs_filtered_asso_straight = {}\n",
    "dfs_filtered_asso_nostraight = {}\n",
    "for wk in wks:\n",
    "    dfs_filtered_asso[wk] = {}\n",
    "    dfs_filtered_asso_straight[wk] = {}\n",
    "    dfs_filtered_asso_nostraight[wk] = {}\n",
    "    for epi in epis:\n",
    "        print(wk, epi)\n",
    "        df_combined = deepcopy(dfs_combined_asso[wk][epi])\n",
    "        print(df_combined.shape)\n",
    "        th_delta = (straight_paired(df_combined)[[\"supp_diff\",\"conf_diff\",\"lift_diff\"]].abs().quantile(0.99)).tolist()\n",
    "        df_filtered = rule_filter(df_combined,\n",
    "                                  config_specific[\"thresholds_for_rule_mining\"][wk][epi][0] + th_delta[0],\n",
    "                                  config_specific[\"thresholds_for_rule_mining\"][wk][epi][1] + th_delta[1],\n",
    "                                  config_specific[\"thresholds_for_rule_mining\"][wk][epi][2] + th_delta[2])\n",
    "        dfs_filtered_asso[wk][epi] = deepcopy(df_filtered)\n",
    "        dfs_filtered_asso_straight[wk][epi] = deepcopy(straight_paired(df_filtered))\n",
    "        dfs_filtered_asso_nostraight[wk][epi] = deepcopy(nostraight_paired(df_filtered))\n",
    "        print(dfs_filtered_asso_nostraight[wk][epi].shape)\n",
    "        print(nostraight_pair_rulenum(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_close_rules(ruleset):\n",
    "    Xs = ruleset[\"X\"].apply(lambda x : ast.literal_eval(x))\n",
    "    Ys = ruleset[\"Y\"].apply(lambda x : ast.literal_eval(x))\n",
    "    idx_to_remove = []\n",
    "    idx_parent = []\n",
    "    for idx, X, Y in zip(range(ruleset.shape[0]), Xs, Ys):\n",
    "        for idxx, X_, Y_ in zip(range(ruleset.shape[0]), Xs, Ys):\n",
    "            if ((set(X) < set(X_) and set(Y) <= set(Y_))\n",
    "               or \n",
    "               (set(X) <= set(X_) and set(Y) < set(Y_))):\n",
    "                idx_to_remove.append(idx)\n",
    "                idx_parent.append(idxx)\n",
    "                break\n",
    "    return ruleset.drop(ruleset.index[idx_to_remove])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule pair - straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "w1 = 1.0\n",
    "w2 = 1.5\n",
    "w3 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not os.path.exists(focus_path + \"SPMF_select/\")):\n",
    "    os.mkdir(focus_path + \"SPMF_select/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesets_asso_straight = {}\n",
    "for wk in wks:\n",
    "    rulesets_asso_straight[wk] = {}\n",
    "    for epi in epis:\n",
    "        df_filtered = deepcopy(dfs_filtered_asso_straight[wk][epi])\n",
    "        # for row_idx, row_filter in deepcopy(df_filtered).iterrows():\n",
    "        df_filtered[\"p_y1\"] = df_filtered[\"conf_grp1\"] / df_filtered[\"lift_grp1\"]\n",
    "        df_filtered[\"p_y2\"] = df_filtered[\"conf_grp2\"] / df_filtered[\"lift_grp2\"]\n",
    "        df_filtered[\"p_x1\"] = df_filtered[\"supp_grp1\"] / df_filtered[\"conf_grp1\"]\n",
    "        df_filtered[\"p_x2\"] = df_filtered[\"supp_grp2\"] / df_filtered[\"conf_grp2\"]\n",
    "\n",
    "        X_len = df_filtered[\"X\"].apply(lambda x : len(ast.literal_eval(x)))\n",
    "        df_filtered[\"delta_p_x\"] = df_filtered[\"p_x1\"] - df_filtered[\"p_x2\"]\n",
    "        delta_supp_1 = 2 * df_filtered[\"supp_diff\"] / (df_filtered[\"p_y1\"] + df_filtered[\"p_y2\"])\n",
    "        delta_supp_2 = (df_filtered[\"p_y2\"] - df_filtered[\"p_y1\"]) * (df_filtered[\"supp_grp1\"] + df_filtered[\"supp_grp2\"]) / (df_filtered[\"p_y1\"] + df_filtered[\"p_y2\"])\n",
    "        df_filtered[\"supp_delta\"] = delta_supp_1 + delta_supp_2\n",
    "        \n",
    "        df_filtered[\"new_three_weight\"] = np.sign(df_filtered[\"delta_p_x\"]) * np.sign(df_filtered[\"conf_diff\"]) *\\\n",
    "                                          np.power(X_len,w1) * \\\n",
    "                                          np.power(np.abs(df_filtered[\"delta_p_x\"]),w2) * \\\n",
    "                                          np.power(np.abs(df_filtered[\"conf_diff\"]),w3)\n",
    "        ruleset1 = deepcopy(df_filtered.sort_values(by = [\"new_three_weight\"], ascending=False).head(top_k))\n",
    "\n",
    "        ruleset_asso_straight = pd.concat([ruleset1])\n",
    "\n",
    "        ruleset_asso_straight.drop_duplicates(inplace=True)\n",
    "        print(\"remove {} duplicates\".format(ruleset1.shape[0] - ruleset_asso_straight.shape[0]))\n",
    "        ruleset_asso_straight_ = deepcopy(remove_close_rules(ruleset_asso_straight))\n",
    "        print(\"remove {} closeset\".format(ruleset_asso_straight.shape[0] - ruleset_asso_straight_.shape[0]))\n",
    "        ruleset_asso_straight = deepcopy(ruleset_asso_straight_)\n",
    "        print(\"final shape\", ruleset_asso_straight.shape)\n",
    "\n",
    "        rulesets_asso_straight[wk][epi] = deepcopy(ruleset_asso_straight)\n",
    "        ruleset_asso_straight.to_csv(focus_path + \"SPMF_select/\" + \"asso_rule_straight\" + \"_\" + wk + \"_\" + epi + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule pair - not-straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesets_asso_nostraight = {}\n",
    "for wk in wks:\n",
    "    rulesets_asso_nostraight[wk] = {}\n",
    "    for epi in epis:\n",
    "        df_filtered = deepcopy(dfs_filtered_asso_nostraight[wk][epi])\n",
    "        # for row_idx, row_filter in deepcopy(df_filtered).iterrows():\n",
    "        df_filtered[\"p_x1\"] = 0\n",
    "        df_filtered[\"p_x2\"] = 0\n",
    "        df_filtered[\"p_y1\"] = 0\n",
    "        df_filtered[\"p_y2\"] = 0\n",
    "\n",
    "        flag_grp1 = df_filtered[\"idx_grp1\"] == 0\n",
    "        df_filtered[\"p_y1\"][flag_grp1] = 0\n",
    "        df_filtered[\"p_y2\"][flag_grp1] = df_filtered[flag_grp1][\"conf_grp2\"] / df_filtered[flag_grp1][\"lift_grp2\"]\n",
    "        df_filtered[\"p_x1\"][flag_grp1] = 0\n",
    "        df_filtered[\"p_x2\"][flag_grp1] = df_filtered[flag_grp1][\"supp_grp2\"] / df_filtered[flag_grp1][\"conf_grp2\"]\n",
    "\n",
    "        flag_grp2 = df_filtered[\"idx_grp2\"] == 0\n",
    "        df_filtered[\"p_y1\"][flag_grp2] = df_filtered[flag_grp2][\"conf_grp1\"] / df_filtered[flag_grp2][\"lift_grp1\"]\n",
    "        df_filtered[\"p_y2\"][flag_grp2] = 0\n",
    "        df_filtered[\"p_x1\"][flag_grp2] = df_filtered[flag_grp2][\"supp_grp1\"] / df_filtered[flag_grp2][\"conf_grp1\"]\n",
    "        df_filtered[\"p_x2\"][flag_grp2] = 0\n",
    "\n",
    "        X_len = df_filtered[\"X\"].apply(lambda x : len(ast.literal_eval(x)))\n",
    "        df_filtered[\"delta_p_x\"] = df_filtered[\"p_x1\"] - df_filtered[\"p_x2\"]\n",
    "        delta_supp_1 = 2 * df_filtered[\"supp_diff\"] / (df_filtered[\"p_y1\"] + df_filtered[\"p_y2\"])\n",
    "        delta_supp_2 = (df_filtered[\"p_y2\"] - df_filtered[\"p_y1\"]) * (df_filtered[\"supp_grp1\"] + df_filtered[\"supp_grp2\"]) / (df_filtered[\"p_y1\"] + df_filtered[\"p_y2\"])\n",
    "        df_filtered[\"supp_delta\"] = delta_supp_1 + delta_supp_2\n",
    "        df_filtered[\"new_three_weight\"] = np.sign(df_filtered[\"delta_p_x\"]) * np.sign(df_filtered[\"conf_diff\"]) *\\\n",
    "                                          np.power(X_len,w1) * \\\n",
    "                                          np.power(np.abs(df_filtered[\"delta_p_x\"]),w2) * \\\n",
    "                                          np.power(np.abs(df_filtered[\"conf_diff\"]),w3)\n",
    "        ruleset1 = deepcopy(df_filtered.sort_values(by = [\"new_three_weight\"], ascending=False).head(top_k))\n",
    "\n",
    "        ruleset_asso_nostraight = pd.concat([ruleset1])\n",
    "        ruleset_asso_nostraight_ = ruleset_asso_nostraight.drop_duplicates()\n",
    "        print(\"remove {} duplicates\".format(ruleset_asso_nostraight_.shape[0] - ruleset_asso_nostraight.shape[0]))\n",
    "        rulesets_asso_nostraight[wk][epi] = deepcopy(ruleset_asso_nostraight_)\n",
    "        print(\"final shape\", ruleset_asso_nostraight.shape)\n",
    "\n",
    "        ruleset_asso_nostraight.to_csv(focus_path + \"SPMF_select/\" + \"asso_rule_nostraight\" + \"_\" + wk + \"_\" + epi + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
